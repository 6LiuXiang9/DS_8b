from unsloth import FastLanguageModel
import torch
import os
import time
import psutil
import threading
from transformers import TextIteratorStreamer
from threading import Thread
from collections import deque
import math

# å°è¯•å¯¼å…¥GPUç›‘æ§åº“
try:
    import pynvml

    pynvml.nvmlInit()
    HAS_PYNVML = True
    gpu_handle = pynvml.nvmlDeviceGetHandleByIndex(0)
except:
    HAS_PYNVML = False
    gpu_handle = None


class AdvancedPerformanceMonitor:
    """é«˜çº§æ€§èƒ½ç›‘æ§å™¨ - åŒ…å«æ¨ç†é€Ÿåº¦ã€å›å¤é€Ÿåº¦å’Œå†…å­˜å³°å€¼çš„ç²¾ç¡®è®¡ç®—"""

    def __init__(self):
        self.start_time = None
        self.metrics = []
        self.monitoring = False

        # é€Ÿåº¦è®¡ç®—ç›¸å…³
        self.inference_start_time = None
        self.first_token_time = None
        self.generation_end_time = None

        # Tokenè®¡æ•°
        self.input_tokens = 0
        self.output_tokens = 0
        self.real_time_tokens = 0

        # å®æ—¶é€Ÿåº¦è·Ÿè¸ª
        self.token_timestamps = []
        self.response_chunks = []

        # å†…å­˜å³°å€¼è·Ÿè¸ª
        self.memory_baseline = None
        self.system_memory_peak = 0
        self.gpu_memory_peak = 0
        self.pytorch_memory_peak = 0
        self.memory_snapshots = []

    def start(self):
        """å¼€å§‹ç›‘æ§"""
        self.start_time = time.time()
        self.monitoring = True
        self.metrics = []
        self.token_timestamps = []
        self.response_chunks = []
        self.memory_snapshots = []

        # è®°å½•å†…å­˜åŸºçº¿
        self.record_memory_baseline()

    def record_memory_baseline(self):
        """è®°å½•å†…å­˜ä½¿ç”¨åŸºçº¿"""
        # ç³»ç»Ÿå†…å­˜
        memory = psutil.virtual_memory()
        self.memory_baseline = {
            'system_memory_used': memory.used / 1024 ** 3,  # GB
            'system_memory_percent': memory.percent,
        }

        # GPUå†…å­˜
        if torch.cuda.is_available():
            self.memory_baseline['gpu_memory_allocated'] = torch.cuda.memory_allocated() / 1024 ** 3
            self.memory_baseline['gpu_memory_reserved'] = torch.cuda.memory_reserved() / 1024 ** 3

            if HAS_PYNVML and gpu_handle:
                try:
                    mem_info = pynvml.nvmlDeviceGetMemoryInfo(gpu_handle)
                    self.memory_baseline['gpu_memory_used'] = mem_info.used / 1024 ** 3
                    self.memory_baseline['gpu_memory_total'] = mem_info.total / 1024 ** 3
                except:
                    pass

        print(f"[å†…å­˜åŸºçº¿] ç³»ç»Ÿå†…å­˜: {self.memory_baseline['system_memory_used']:.2f}GB "
              f"({self.memory_baseline['system_memory_percent']:.1f}%)")
        if torch.cuda.is_available():
            print(f"[å†…å­˜åŸºçº¿] GPUå†…å­˜: {self.memory_baseline.get('gpu_memory_allocated', 0):.2f}GB")

    def update_memory_peaks(self):
        """æ›´æ–°å†…å­˜å³°å€¼è®°å½•"""
        # ç³»ç»Ÿå†…å­˜
        memory = psutil.virtual_memory()
        current_system_memory = memory.used / 1024 ** 3
        self.system_memory_peak = max(self.system_memory_peak, current_system_memory)

        # GPUå†…å­˜
        if torch.cuda.is_available():
            current_pytorch_allocated = torch.cuda.memory_allocated() / 1024 ** 3
            current_pytorch_reserved = torch.cuda.memory_reserved() / 1024 ** 3

            self.pytorch_memory_peak = max(self.pytorch_memory_peak, current_pytorch_allocated)

            if HAS_PYNVML and gpu_handle:
                try:
                    mem_info = pynvml.nvmlDeviceGetMemoryInfo(gpu_handle)
                    current_gpu_memory = mem_info.used / 1024 ** 3
                    self.gpu_memory_peak = max(self.gpu_memory_peak, current_gpu_memory)
                except:
                    pass

        # è®°å½•è¯¦ç»†å¿«ç…§ (æ¯ç§’è®°å½•ä¸€æ¬¡ä»¥é¿å…è¿‡å¤šæ•°æ®)
        current_time = time.time()
        if not self.memory_snapshots or (current_time - self.memory_snapshots[-1]['timestamp']) >= 1.0:
            snapshot = {
                'timestamp': current_time - self.start_time,
                'system_memory': current_system_memory,
                'system_memory_percent': memory.percent,
            }

            if torch.cuda.is_available():
                snapshot['pytorch_allocated'] = current_pytorch_allocated
                snapshot['pytorch_reserved'] = current_pytorch_reserved

                if HAS_PYNVML and gpu_handle:
                    try:
                        mem_info = pynvml.nvmlDeviceGetMemoryInfo(gpu_handle)
                        snapshot['gpu_memory_used'] = mem_info.used / 1024 ** 3
                        snapshot['gpu_memory_utilization'] = (mem_info.used / mem_info.total) * 100
                    except:
                        pass

            self.memory_snapshots.append(snapshot)

    def start_inference_timing(self, input_token_count):
        """å¼€å§‹æ¨ç†è®¡æ—¶"""
        self.inference_start_time = time.time()
        self.input_tokens = input_token_count
        self.output_tokens = 0
        self.real_time_tokens = 0
        print(f"[DEBUG] æ¨ç†å¼€å§‹ï¼Œè¾“å…¥Tokenæ•°: {input_token_count}")

    def record_first_token(self):
        """è®°å½•é¦–ä¸ªTokenç”Ÿæˆæ—¶é—´"""
        if self.first_token_time is None:
            self.first_token_time = time.time()
            first_token_latency = self.first_token_time - self.inference_start_time
            print(f"[DEBUG] é¦–Tokenå»¶è¿Ÿ: {first_token_latency:.3f}ç§’")
            return first_token_latency
        return None

    def record_token_generation(self, new_text):
        """è®°å½•æ¯ä¸ªTokenç”Ÿæˆçš„æ—¶é—´"""
        current_time = time.time()
        self.token_timestamps.append(current_time)
        self.response_chunks.append(new_text)
        self.real_time_tokens += 1

    def end_inference_timing(self, total_generated_text):
        """ç»“æŸæ¨ç†è®¡æ—¶å¹¶è®¡ç®—æœ€ç»ˆç»Ÿè®¡"""
        self.generation_end_time = time.time()

        # ä½¿ç”¨tokenizerç²¾ç¡®è®¡ç®—è¾“å‡ºTokenæ•°
        if hasattr(self, 'tokenizer') and self.tokenizer:
            self.output_tokens = len(self.tokenizer.encode(total_generated_text))
        else:
            # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨å®æ—¶è®¡æ•°
            self.output_tokens = self.real_time_tokens

        print(f"[DEBUG] æ¨ç†ç»“æŸï¼Œè¾“å‡ºTokenæ•°: {self.output_tokens}")

    def collect_snapshot(self):
        """æ”¶é›†å½“å‰èµ„æºä½¿ç”¨å¿«ç…§"""
        if not self.monitoring:
            return

        snapshot = {
            'timestamp': time.time() - self.start_time,
            'cpu': psutil.cpu_percent(),
        }

        # æ›´æ–°å†…å­˜å³°å€¼
        self.update_memory_peaks()

        if torch.cuda.is_available():
            snapshot['gpu_memory_allocated'] = torch.cuda.memory_allocated() / 1024 ** 3
            snapshot['gpu_memory_reserved'] = torch.cuda.memory_reserved() / 1024 ** 3

            if HAS_PYNVML and gpu_handle:
                try:
                    util = pynvml.nvmlDeviceGetUtilizationRates(gpu_handle)
                    snapshot['gpu_usage'] = util.gpu

                    mem_info = pynvml.nvmlDeviceGetMemoryInfo(gpu_handle)
                    snapshot['gpu_memory_percent'] = (mem_info.used / mem_info.total) * 100

                    # è·å–GPUæ¸©åº¦å’ŒåŠŸè€—
                    try:
                        snapshot['gpu_temp'] = pynvml.nvmlDeviceGetTemperature(
                            gpu_handle, pynvml.NVML_TEMPERATURE_GPU)
                    except:
                        pass
                    try:
                        snapshot['gpu_power'] = pynvml.nvmlDeviceGetPowerUsage(gpu_handle) / 1000.0  # W
                    except:
                        pass
                except:
                    pass

        self.metrics.append(snapshot)

    def stop(self):
        """åœæ­¢ç›‘æ§"""
        self.monitoring = False

    def calculate_speeds(self):
        """è®¡ç®—å„ç§é€Ÿåº¦æŒ‡æ ‡"""
        if not self.inference_start_time or not self.generation_end_time:
            return {}

        # åŸºç¡€æ—¶é—´è®¡ç®—
        total_inference_time = self.generation_end_time - self.inference_start_time
        first_token_latency = (self.first_token_time - self.inference_start_time) if self.first_token_time else 0
        generation_time = self.generation_end_time - self.first_token_time if self.first_token_time else total_inference_time

        speeds = {
            # æ—¶é—´æŒ‡æ ‡
            'total_inference_time': total_inference_time,
            'first_token_latency': first_token_latency,
            'pure_generation_time': generation_time,

            # Tokenè®¡æ•°
            'input_tokens': self.input_tokens,
            'output_tokens': self.output_tokens,
            'total_tokens': self.input_tokens + self.output_tokens,
        }

        # è®¡ç®—å„ç§é€Ÿåº¦
        if total_inference_time > 0:
            # 1. æ€»ä½“æ¨ç†é€Ÿåº¦ (åŒ…æ‹¬é¦–Tokenå»¶è¿Ÿ)
            speeds['total_inference_speed'] = self.output_tokens / total_inference_time

            # 2. æ•´ä½“å¤„ç†é€Ÿåº¦ (è¾“å…¥+è¾“å‡º)
            speeds['overall_processing_speed'] = (self.input_tokens + self.output_tokens) / total_inference_time

        if generation_time > 0 and self.output_tokens > 1:
            # 3. çº¯ç”Ÿæˆé€Ÿåº¦ (æ’é™¤é¦–Tokenå»¶è¿Ÿ)
            speeds['pure_generation_speed'] = (self.output_tokens - 1) / generation_time

            # 4. å›å¤é€Ÿåº¦ (ä»é¦–Tokenå¼€å§‹çš„è¿ç»­ç”Ÿæˆé€Ÿåº¦)
            speeds['response_speed'] = (self.output_tokens - 1) / generation_time

        # 5. å®æ—¶å¹³å‡é€Ÿåº¦è®¡ç®—
        if len(self.token_timestamps) > 1:
            time_intervals = []
            for i in range(1, len(self.token_timestamps)):
                interval = self.token_timestamps[i] - self.token_timestamps[i - 1]
                if interval > 0:
                    time_intervals.append(interval)

            if time_intervals:
                avg_interval = sum(time_intervals) / len(time_intervals)
                speeds['real_time_avg_speed'] = 1.0 / avg_interval if avg_interval > 0 else 0
                speeds['real_time_intervals'] = time_intervals

        return speeds

    def get_summary(self):
        """è·å–å®Œæ•´çš„ç›‘æ§æ‘˜è¦"""
        if not self.metrics:
            return {}

        cpu_values = [m['cpu'] for m in self.metrics]
        summary = {
            'duration': self.metrics[-1]['timestamp'],
            'cpu_avg': sum(cpu_values) / len(cpu_values),
            'cpu_max': max(cpu_values),
            'cpu_min': min(cpu_values),
        }

        # å†…å­˜å³°å€¼ä¿¡æ¯
        summary['memory_peaks'] = {
            'system_memory_peak': self.system_memory_peak,
            'pytorch_memory_peak': self.pytorch_memory_peak,
            'gpu_memory_peak': self.gpu_memory_peak,
        }

        # å†…å­˜å¢é•¿åˆ†æ
        if self.memory_baseline:
            baseline_system = self.memory_baseline.get('system_memory_used', 0)
            baseline_pytorch = self.memory_baseline.get('gpu_memory_allocated', 0)

            summary['memory_growth'] = {
                'system_memory_growth': self.system_memory_peak - baseline_system,
                'pytorch_memory_growth': self.pytorch_memory_peak - baseline_pytorch,
            }

        if torch.cuda.is_available():
            gpu_mem_values = [m.get('gpu_memory_allocated', 0) for m in self.metrics]
            summary['gpu_memory_avg'] = sum(gpu_mem_values) / len(gpu_mem_values)

            if any('gpu_usage' in m for m in self.metrics):
                gpu_usage_values = [m['gpu_usage'] for m in self.metrics if 'gpu_usage' in m]
                summary['gpu_usage_avg'] = sum(gpu_usage_values) / len(gpu_usage_values)
                summary['gpu_usage_max'] = max(gpu_usage_values)
                summary['gpu_usage_min'] = min(gpu_usage_values)

            if any('gpu_temp' in m for m in self.metrics):
                gpu_temp_values = [m['gpu_temp'] for m in self.metrics if 'gpu_temp' in m]
                summary['gpu_temp_avg'] = sum(gpu_temp_values) / len(gpu_temp_values)
                summary['gpu_temp_max'] = max(gpu_temp_values)

            if any('gpu_power' in m for m in self.metrics):
                gpu_power_values = [m['gpu_power'] for m in self.metrics if 'gpu_power' in m]
                summary['gpu_power_avg'] = sum(gpu_power_values) / len(gpu_power_values)
                summary['gpu_power_max'] = max(gpu_power_values)

        return summary

    def get_memory_analysis(self):
        """è·å–è¯¦ç»†çš„å†…å­˜åˆ†æ"""
        if not self.memory_snapshots:
            return {}

        analysis = {
            'baseline': self.memory_baseline,
            'peaks': {
                'system_memory_peak': self.system_memory_peak,
                'pytorch_memory_peak': self.pytorch_memory_peak,
                'gpu_memory_peak': self.gpu_memory_peak,
            }
        }

        # è®¡ç®—å†…å­˜ä½¿ç”¨è¶‹åŠ¿
        if len(self.memory_snapshots) > 1:
            system_memories = [s['system_memory'] for s in self.memory_snapshots]
            pytorch_memories = [s.get('pytorch_allocated', 0) for s in self.memory_snapshots]

            analysis['trends'] = {
                'system_memory_trend': 'increasing' if system_memories[-1] > system_memories[0] else 'stable',
                'pytorch_memory_trend': 'increasing' if pytorch_memories[-1] > pytorch_memories[0] else 'stable',
                'system_memory_variance': max(system_memories) - min(system_memories),
                'pytorch_memory_variance': max(pytorch_memories) - min(pytorch_memories),
            }

        # å†…å­˜æ•ˆç‡åˆ†æ
        if self.memory_baseline and torch.cuda.is_available():
            baseline_pytorch = self.memory_baseline.get('gpu_memory_allocated', 0)
            model_memory_footprint = self.pytorch_memory_peak - baseline_pytorch

            analysis['efficiency'] = {
                'model_memory_footprint': model_memory_footprint,
                'memory_efficiency': 'good' if model_memory_footprint < 6 else 'high' if model_memory_footprint < 8 else 'very_high'
            }

        return analysis


def print_detailed_performance_report(speeds, summary, memory_analysis):
    """æ‰“å°è¯¦ç»†çš„æ€§èƒ½æŠ¥å‘Š"""

    print(f"\n{'=' * 80}")
    print("ğŸ”¥ è¯¦ç»†æ€§èƒ½åˆ†ææŠ¥å‘Š")
    print(f"{'=' * 80}")

    # 1. é€Ÿåº¦æŒ‡æ ‡åˆ†æ
    print(f"\nğŸ“Š é€Ÿåº¦æŒ‡æ ‡åˆ†æ:")
    print(f"{'-' * 50}")

    if speeds:
        print(f"â±ï¸  é¦–Tokenå»¶è¿Ÿ: {speeds.get('first_token_latency', 0):.3f} ç§’")
        print(f"â±ï¸  æ€»æ¨ç†æ—¶é—´: {speeds.get('total_inference_time', 0):.3f} ç§’")
        print(f"â±ï¸  çº¯ç”Ÿæˆæ—¶é—´: {speeds.get('pure_generation_time', 0):.3f} ç§’")

        print(f"\nğŸ”¢ Token ç»Ÿè®¡:")
        print(f"   è¾“å…¥ Tokens: {speeds.get('input_tokens', 0)}")
        print(f"   è¾“å‡º Tokens: {speeds.get('output_tokens', 0)}")
        print(f"   æ€»è®¡ Tokens: {speeds.get('total_tokens', 0)}")

        print(f"\nğŸš€ æ¨ç†é€Ÿåº¦ (å…³é”®æŒ‡æ ‡):")
        total_speed = speeds.get('total_inference_speed', 0)
        pure_speed = speeds.get('pure_generation_speed', 0)
        response_speed = speeds.get('response_speed', 0)
        realtime_speed = speeds.get('real_time_avg_speed', 0)

        print(f"   ğŸ“ˆ æ€»ä½“æ¨ç†é€Ÿåº¦: {total_speed:.2f} tokens/ç§’ (åŒ…å«é¦–Tokenå»¶è¿Ÿ)")
        print(f"   âš¡ çº¯ç”Ÿæˆé€Ÿåº¦: {pure_speed:.2f} tokens/ç§’ (æ’é™¤é¦–Tokenå»¶è¿Ÿ)")
        print(f"   ğŸ’¬ å›å¤é€Ÿåº¦: {response_speed:.2f} tokens/ç§’ (è¿ç»­ç”Ÿæˆé€Ÿåº¦)")
        print(f"   ğŸ“Š å®æ—¶å¹³å‡é€Ÿåº¦: {realtime_speed:.2f} tokens/ç§’ (åŸºäºå®é™…é—´éš”)")

        # é€Ÿåº¦è¯„çº§
        print(f"\nğŸ“ é€Ÿåº¦è¯„çº§:")
        speed_to_evaluate = pure_speed  # ä½¿ç”¨çº¯ç”Ÿæˆé€Ÿåº¦ä½œä¸ºä¸»è¦è¯„ä¼°æŒ‡æ ‡

        if speed_to_evaluate > 30:
            rating = "ğŸ† ä¼˜ç§€ (Excellent)"
            color = "âœ…"
        elif speed_to_evaluate > 20:
            rating = "ğŸ¥‡ è‰¯å¥½ (Good)"
            color = "ğŸŸ¢"
        elif speed_to_evaluate > 15:
            rating = "ğŸ¥ˆ ä¸­ç­‰ (Average)"
            color = "ğŸŸ¡"
        elif speed_to_evaluate > 10:
            rating = "ğŸ¥‰ åä½ (Below Average)"
            color = "ğŸŸ "
        else:
            rating = "âŒ éœ€è¦ä¼˜åŒ– (Needs Optimization)"
            color = "ğŸ”´"

        print(f"   {color} çº¯ç”Ÿæˆé€Ÿåº¦è¯„çº§: {rating}")

        # é¦–Tokenå»¶è¿Ÿè¯„çº§
        latency = speeds.get('first_token_latency', 0)
        if latency < 0.5:
            latency_rating = "ğŸ† ä¼˜ç§€ (<0.5s)"
        elif latency < 1.0:
            latency_rating = "ğŸŸ¢ è‰¯å¥½ (<1.0s)"
        elif latency < 2.0:
            latency_rating = "ğŸŸ¡ ä¸­ç­‰ (<2.0s)"
        else:
            latency_rating = "ğŸ”´ éœ€è¦ä¼˜åŒ– (>2.0s)"

        print(f"   {latency_rating[:2]} é¦–Tokenå»¶è¿Ÿè¯„çº§: {latency_rating[2:]}")

    # 2. å†…å­˜ä½¿ç”¨åˆ†æ
    print(f"\nğŸ’¾ å†…å­˜ä½¿ç”¨åˆ†æ:")
    print(f"{'-' * 50}")

    if memory_analysis:
        baseline = memory_analysis.get('baseline', {})
        peaks = memory_analysis.get('peaks', {})
        trends = memory_analysis.get('trends', {})
        efficiency = memory_analysis.get('efficiency', {})

        print(f"ğŸ”§ å†…å­˜åŸºçº¿:")
        if baseline:
            print(f"   ç³»ç»Ÿå†…å­˜åŸºçº¿: {baseline.get('system_memory_used', 0):.2f} GB "
                  f"({baseline.get('system_memory_percent', 0):.1f}%)")
            print(f"   GPUå†…å­˜åŸºçº¿: {baseline.get('gpu_memory_allocated', 0):.2f} GB")

        print(f"\nğŸ“ˆ å†…å­˜å³°å€¼:")
        system_peak = peaks.get('system_memory_peak', 0)
        pytorch_peak = peaks.get('pytorch_memory_peak', 0)
        gpu_peak = peaks.get('gpu_memory_peak', 0)

        print(f"   ç³»ç»Ÿå†…å­˜å³°å€¼: {system_peak:.2f} GB")
        print(f"   PyTorch GPUå†…å­˜å³°å€¼: {pytorch_peak:.2f} GB")
        if gpu_peak > 0:
            print(f"   GPUæ˜¾å­˜å³°å€¼: {gpu_peak:.2f} GB")

        # å†…å­˜å¢é•¿åˆ†æ
        if baseline and summary and 'memory_growth' in summary:
            growth = summary['memory_growth']
            system_growth = growth.get('system_memory_growth', 0)
            pytorch_growth = growth.get('pytorch_memory_growth', 0)

            print(f"\nğŸ“Š å†…å­˜å¢é•¿:")
            print(f"   ç³»ç»Ÿå†…å­˜å¢é•¿: {system_growth:.2f} GB")
            print(f"   GPUå†…å­˜å¢é•¿: {pytorch_growth:.2f} GB")

            # å†…å­˜å¢é•¿è¯„ä¼°
            if pytorch_growth < 1.0:
                print(f"   âœ… GPUå†…å­˜å¢é•¿åˆç†")
            elif pytorch_growth < 2.0:
                print(f"   ğŸŸ¡ GPUå†…å­˜å¢é•¿ä¸­ç­‰")
            else:
                print(f"   âš ï¸  GPUå†…å­˜å¢é•¿è¾ƒå¤§")

        # å†…å­˜æ•ˆç‡åˆ†æ
        if efficiency:
            model_footprint = efficiency.get('model_memory_footprint', 0)
            memory_efficiency = efficiency.get('memory_efficiency', 'unknown')

            print(f"\nğŸ¯ å†…å­˜æ•ˆç‡:")
            print(f"   æ¨¡å‹å†…å­˜å ç”¨: {model_footprint:.2f} GB")

            if memory_efficiency == 'good':
                print(f"   âœ… å†…å­˜ä½¿ç”¨æ•ˆç‡: ä¼˜ç§€ (<6GB)")
            elif memory_efficiency == 'high':
                print(f"   ğŸŸ¡ å†…å­˜ä½¿ç”¨æ•ˆç‡: ä¸­ç­‰ (6-8GB)")
            else:
                print(f"   ğŸ”´ å†…å­˜ä½¿ç”¨æ•ˆç‡: éœ€ä¼˜åŒ– (>8GB)")

        # å†…å­˜è¶‹åŠ¿åˆ†æ
        if trends:
            print(f"\nğŸ“‰ å†…å­˜è¶‹åŠ¿:")
            sys_trend = trends.get('system_memory_trend', 'unknown')
            pytorch_trend = trends.get('pytorch_memory_trend', 'unknown')

            print(f"   ç³»ç»Ÿå†…å­˜è¶‹åŠ¿: {sys_trend}")
            print(f"   GPUå†…å­˜è¶‹åŠ¿: {pytorch_trend}")

            sys_variance = trends.get('system_memory_variance', 0)
            pytorch_variance = trends.get('pytorch_memory_variance', 0)

            print(f"   ç³»ç»Ÿå†…å­˜æ³¢åŠ¨: {sys_variance:.2f} GB")
            print(f"   GPUå†…å­˜æ³¢åŠ¨: {pytorch_variance:.2f} GB")

    # 3. èµ„æºä½¿ç”¨åˆ†æ
    print(f"\nğŸ’» èµ„æºä½¿ç”¨åˆ†æ:")
    print(f"{'-' * 50}")

    if summary:
        print(f"ğŸ”§ CPU ä½¿ç”¨æƒ…å†µ:")
        cpu_avg = summary.get('cpu_avg', 0)
        cpu_max = summary.get('cpu_max', 0)
        print(f"   å¹³å‡ä½¿ç”¨ç‡: {cpu_avg:.1f}%")
        print(f"   å³°å€¼ä½¿ç”¨ç‡: {cpu_max:.1f}%")

        if cpu_avg > 80:
            print(f"   âš ï¸  CPUä½¿ç”¨ç‡è¾ƒé«˜ï¼Œå¯èƒ½æˆä¸ºç“¶é¢ˆ")
        elif cpu_avg < 20:
            print(f"   âœ… CPUä½¿ç”¨ç‡æ­£å¸¸ï¼ŒGPUä¸ºä¸»è¦è®¡ç®—å•å…ƒ")

        if torch.cuda.is_available():
            print(f"\nğŸ® GPU ä½¿ç”¨æƒ…å†µ:")
            gpu_usage_avg = summary.get('gpu_usage_avg', 0)
            gpu_usage_max = summary.get('gpu_usage_max', 0)
            gpu_memory_avg = summary.get('gpu_memory_avg', 0)

            print(f"   è®¡ç®—ä½¿ç”¨ç‡ - å¹³å‡: {gpu_usage_avg:.1f}%, å³°å€¼: {gpu_usage_max:.1f}%")
            print(f"   æ˜¾å­˜ä½¿ç”¨ - å¹³å‡: {gpu_memory_avg:.2f}GB")

            if 'gpu_temp_avg' in summary:
                print(f"   æ¸©åº¦ - å¹³å‡: {summary['gpu_temp_avg']:.1f}Â°C, "
                      f"å³°å€¼: {summary['gpu_temp_max']:.1f}Â°C")
            if 'gpu_power_avg' in summary:
                print(f"   åŠŸè€— - å¹³å‡: {summary['gpu_power_avg']:.1f}W, "
                      f"å³°å€¼: {summary['gpu_power_max']:.1f}W")

            # GPUä½¿ç”¨ç‡è¯„ä¼°
            if gpu_usage_avg > 85:
                print(f"   âœ… GPUä½¿ç”¨ç‡ä¼˜ç§€ï¼Œè®¡ç®—èµ„æºå……åˆ†åˆ©ç”¨")
            elif gpu_usage_avg > 70:
                print(f"   ğŸŸ¡ GPUä½¿ç”¨ç‡è‰¯å¥½")
            else:
                print(f"   âš ï¸  GPUä½¿ç”¨ç‡åä½ï¼Œå¯èƒ½å­˜åœ¨ç“¶é¢ˆ")

    # 4. ä¼˜åŒ–å»ºè®®
    print(f"\nğŸ› ï¸  ä¼˜åŒ–å»ºè®®:")
    print(f"{'-' * 50}")

    suggestions = []

    if speeds:
        if speeds.get('first_token_latency', 0) > 1.5:
            suggestions.append("ğŸ”¥ æ·»åŠ æ¨¡å‹é¢„çƒ­æ¥å‡å°‘é¦–Tokenå»¶è¿Ÿ")

        if speeds.get('pure_generation_speed', 0) < 20:
            suggestions.append("âš¡ è€ƒè™‘ä½¿ç”¨FP16ç²¾åº¦æ›¿ä»£4bité‡åŒ– (å¦‚æœæ˜¾å­˜å……è¶³)")
            suggestions.append("ğŸ”§ æ£€æŸ¥CPU-GPUæ•°æ®ä¼ è¾“æ˜¯å¦å­˜åœ¨ç“¶é¢ˆ")

    if summary:
        if summary.get('gpu_usage_avg', 0) < 70:
            suggestions.append("ğŸ“ˆ GPUåˆ©ç”¨ç‡åä½ï¼Œæ£€æŸ¥æ¨¡å‹é…ç½®å’Œè¾“å…¥æ‰¹æ¬¡å¤§å°")

        if summary.get('cpu_avg', 0) > 70:
            suggestions.append("ğŸš€ ä¼˜åŒ–æ•°æ®é¢„å¤„ç†æµç¨‹ï¼Œå‡å°‘CPUè´Ÿè½½")

    # å†…å­˜ç›¸å…³å»ºè®®
    if memory_analysis:
        efficiency = memory_analysis.get('efficiency', {})
        if efficiency.get('memory_efficiency') == 'very_high':
            suggestions.append("ğŸ’¾ å†…å­˜ä½¿ç”¨é‡å¤§ï¼Œè€ƒè™‘æ›´æ¿€è¿›çš„é‡åŒ–ç­–ç•¥æˆ–æ¨¡å‹åˆ†ç‰‡")

        peaks = memory_analysis.get('peaks', {})
        if peaks.get('pytorch_memory_peak', 0) > 7:  # æ¥è¿‘8GBæ˜¾å­˜é™åˆ¶
            suggestions.append("âš ï¸  GPUå†…å­˜æ¥è¿‘é™åˆ¶ï¼Œå»ºè®®é™ä½max_new_tokensæˆ–ä½¿ç”¨æ›´å°batch size")

    if suggestions:
        for i, suggestion in enumerate(suggestions, 1):
            print(f"   {i}. {suggestion}")
    else:
        print(f"   âœ… å½“å‰æ€§èƒ½è¡¨ç°ä¼˜ç§€ï¼Œæ— éœ€ç‰¹æ®Šä¼˜åŒ–!")

    # 5. ç¡¬ä»¶é…ç½®è¯„ä¼°
    if torch.cuda.is_available():
        print(f"\nğŸ”Œ ç¡¬ä»¶é…ç½®è¯„ä¼°:")
        print(f"{'-' * 50}")
        gpu_name = torch.cuda.get_device_name()
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024 ** 3
        print(f"   GPUå‹å·: {gpu_name}")
        print(f"   æ˜¾å­˜å®¹é‡: {gpu_memory:.1f} GB")

        if "RTX 4060" in gpu_name:
            print(f"   ğŸ’¡ RTX 4060 Laptop GPUé€‚åˆè¿è¡Œ8Bæ¨¡å‹ï¼Œæ€§èƒ½è¡¨ç°ç¬¦åˆé¢„æœŸ")

        if gpu_memory < 8:
            print(f"   âš ï¸  æ˜¾å­˜å®¹é‡åå°ï¼Œå»ºè®®å‡çº§åˆ°8GB+çš„GPU")
        else:
            print(f"   âœ… æ˜¾å­˜å®¹é‡å……è¶³")

        # å†…å­˜åˆ©ç”¨ç‡è¯„ä¼°
        if memory_analysis:
            peaks = memory_analysis.get('peaks', {})
            pytorch_peak = peaks.get('pytorch_memory_peak', 0)
            utilization = (pytorch_peak / gpu_memory) * 100 if gpu_memory > 0 else 0

            print(f"   ğŸ“Š æ˜¾å­˜åˆ©ç”¨ç‡: {utilization:.1f}% ({pytorch_peak:.2f}GB / {gpu_memory:.1f}GB)")

            if utilization > 90:
                print(f"   ğŸ”´ æ˜¾å­˜åˆ©ç”¨ç‡å¾ˆé«˜ï¼Œæ¥è¿‘æ»¡è½½")
            elif utilization > 70:
                print(f"   ğŸŸ¡ æ˜¾å­˜åˆ©ç”¨ç‡è¾ƒé«˜ï¼Œè¿è¡Œè‰¯å¥½")
            elif utilization > 50:
                print(f"   âœ… æ˜¾å­˜åˆ©ç”¨ç‡é€‚ä¸­ï¼Œè¿˜æœ‰ä¼˜åŒ–ç©ºé—´")
            else:
                print(f"   ğŸ’¡ æ˜¾å­˜åˆ©ç”¨ç‡è¾ƒä½ï¼Œå¯è€ƒè™‘è¿è¡Œæ›´å¤§æ¨¡å‹")


def main():
    """ä¸»å‡½æ•°"""
    # Print current working directory to help locate model files
    print(f"Current working directory: {os.getcwd()}")

    # Model configuration
    max_seq_length = 2048
    load_in_4bit = True

    # Path to your saved fine-tuned model
    model_path = "E:/DS_8b/DeepSeek-R1-Medical-COT_910"
    print(f"Loading model from: {model_path}")

    # åˆå§‹åŒ–é«˜çº§ç›‘æ§å™¨
    monitor = AdvancedPerformanceMonitor()

    print("å¼€å§‹æ¨¡å‹åŠ è½½ç›‘æ§...")
    monitor.start()

    # Load the fine-tuned model and tokenizer
    try:
        model, tokenizer = FastLanguageModel.from_pretrained(
            model_name=model_path,
            max_seq_length=max_seq_length,
            load_in_4bit=load_in_4bit,
        )
        # å°†tokenizeræ·»åŠ åˆ°ç›‘æ§å™¨ä¸­ç”¨äºç²¾ç¡®è®¡ç®—
        monitor.tokenizer = tokenizer
        print("Model and tokenizer loaded successfully!")
        monitor.collect_snapshot()  # è®°å½•åŠ è½½åçŠ¶æ€
    except Exception as e:
        print(f"Error loading model: {e}")
        return

    # Set the model to inference mode
    FastLanguageModel.for_inference(model)
    print("Model prepared for inference")

    # Setup prompt template
    test_prompt_template = """Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. Before answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.

### Instruction:
You are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning. Please answer the following medical question.

### Question:
{}

### Response:
"""

    # Test question (dermatology description)
    test_question = "æ ¹æ®æ£€æŸ¥æ‰€è§ï¼šå¤–å‘¨é»„è¤è‰²è‰²ç´ æ²‰ç€ï¼Œä¸­å¤®ç™½è‰²ç˜¢ç—•æ ·æ–‘ç‰‡ï¼Œä¼´ç‚¹çŠ¶åŠçº¿çŠ¶è¡€ç®¡ã€‚ä¼šå¾—åˆ°æ€ä¹ˆæ ·çš„ä¸€ä¸ªç»“æœ"

    print("\nTesting model with question:")
    print(test_question)
    print("\nGenerating response...")

    # Format the question
    formatted_input = test_prompt_template.format(test_question)

    # Tokenize input and count tokens
    inputs = tokenizer([formatted_input], return_tensors="pt")
    input_token_count = inputs.input_ids.shape[1]

    # Move inputs to the same device as the model
    if torch.cuda.is_available():
        device = "cuda"
        inputs = inputs.to(device)
        model = model.to(device)
        print("Using CUDA for inference")
    else:
        device = "cpu"
        print("Using CPU for inference (this might be slow)")

    # è®°å½•æ¨ç†å‰çŠ¶æ€
    monitor.collect_snapshot()

    # é«˜çº§æµå¼ç”Ÿæˆ + ç²¾ç¡®é€Ÿåº¦ç›‘æ§
    print(f"\n{'=' * 80}")
    print("ğŸš€ å¼€å§‹é«˜ç²¾åº¦æ¨ç†é€Ÿåº¦ç›‘æ§")
    print(f"{'=' * 80}")

    # Setup streamer
    streamer = TextIteratorStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)

    # Generation parameters
    generation_kwargs = {
        "input_ids": inputs.input_ids,
        "attention_mask": inputs.attention_mask,
        "max_new_tokens": 1200,
        "temperature": 0.7,
        "top_p": 0.9,
        "use_cache": True,
        "streamer": streamer,
        "do_sample": True,
    }

    # ç›‘æ§æ¨ç†è¿‡ç¨‹
    def monitor_during_generation():
        """æ¨ç†è¿‡ç¨‹ä¸­çš„ç›‘æ§å‡½æ•°"""
        while monitor.monitoring:
            monitor.collect_snapshot()
            time.sleep(0.1)  # æ¯100msé‡‡æ ·ä¸€æ¬¡

    # å¼€å§‹æ¨ç†è®¡æ—¶
    monitor.start_inference_timing(input_token_count)

    # Start generation in a separate thread
    thread = Thread(target=model.generate, kwargs=generation_kwargs)

    # Start monitoring thread
    monitor_thread = Thread(target=monitor_during_generation)
    monitor_thread.daemon = True
    monitor_thread.start()

    thread.start()

    # å®æ—¶ç›‘æ§å’Œè®°å½•
    first_token_received = False
    generated_text = ""
    token_count = 0

    print("ğŸ“ ç”Ÿæˆå“åº”:")
    print(f"{'-' * 60}")
    print("Response: ", end="", flush=True)

    for new_text in streamer:
        if not first_token_received:
            # è®°å½•é¦–Token
            latency = monitor.record_first_token()
            first_token_received = True
            print(f"\n[âš¡ é¦–Tokenå»¶è¿Ÿ: {latency:.3f}ç§’]")
            print("Response: ", end="", flush=True)

        # è®°å½•æ¯ä¸ªtokençš„ç”Ÿæˆæ—¶é—´
        monitor.record_token_generation(new_text)

        print(new_text, end="", flush=True)
        generated_text += new_text
        token_count += 1

    thread.join()

    # ç»“æŸè®¡æ—¶
    monitor.end_inference_timing(generated_text)

    # åœæ­¢ç›‘æ§
    monitor.stop()

    print(f"\n{'-' * 60}")

    # è®¡ç®—è¯¦ç»†é€Ÿåº¦æŒ‡æ ‡
    speeds = monitor.calculate_speeds()
    summary = monitor.get_summary()
    memory_analysis = monitor.get_memory_analysis()

    # æ‰“å°è¯¦ç»†æ€§èƒ½æŠ¥å‘Š
    print_detailed_performance_report(speeds, summary, memory_analysis)

    # PyTorch GPUå†…å­˜è¯¦æƒ…
    if torch.cuda.is_available():
        print(f"\nğŸ”§ PyTorch GPUå†…å­˜è¯¦æƒ…:")
        print(f"{'-' * 50}")
        current_allocated = torch.cuda.memory_allocated() / 1024 ** 3
        current_reserved = torch.cuda.memory_reserved() / 1024 ** 3
        max_allocated = torch.cuda.max_memory_allocated() / 1024 ** 3

        print(f"   å½“å‰å·²åˆ†é…: {current_allocated:.2f} GB")
        print(f"   å½“å‰å·²ä¿ç•™: {current_reserved:.2f} GB")
        print(f"   å³°å€¼å·²åˆ†é…: {max_allocated:.2f} GB")

        # å†…å­˜ç¢ç‰‡åˆ†æ
        memory_fragmentation = current_reserved - current_allocated
        print(f"   å†…å­˜ç¢ç‰‡: {memory_fragmentation:.2f} GB")

        if memory_fragmentation > 1.0:
            print(f"   âš ï¸  å†…å­˜ç¢ç‰‡è¾ƒå¤šï¼Œå»ºè®®å®šæœŸæ¸…ç†GPUç¼“å­˜")
        else:
            print(f"   âœ… å†…å­˜ç¢ç‰‡æ§åˆ¶è‰¯å¥½")

    # å†…å­˜ä½¿ç”¨å†å²åˆ†æ
    if monitor.memory_snapshots and len(monitor.memory_snapshots) > 2:
        print(f"\nğŸ“ˆ å†…å­˜ä½¿ç”¨å†å²åˆ†æ:")
        print(f"{'-' * 50}")

        # åˆ†æå†…å­˜ä½¿ç”¨æ¨¡å¼
        pytorch_memories = [s.get('pytorch_allocated', 0) for s in monitor.memory_snapshots]
        system_memories = [s['system_memory'] for s in monitor.memory_snapshots]
        timestamps = [s['timestamp'] for s in monitor.memory_snapshots]

        # æ‰¾åˆ°å†…å­˜å¢é•¿æœ€å¿«çš„é˜¶æ®µ
        max_pytorch_growth = 0
        max_growth_period = None

        for i in range(1, len(pytorch_memories)):
            growth = pytorch_memories[i] - pytorch_memories[i - 1]
            if growth > max_pytorch_growth:
                max_pytorch_growth = growth
                max_growth_period = (timestamps[i - 1], timestamps[i])

        if max_growth_period:
            print(f"   æœ€å¤§å†…å­˜å¢é•¿: {max_pytorch_growth:.2f} GB")
            print(f"   å¢é•¿æ—¶æ®µ: {max_growth_period[0]:.1f}s - {max_growth_period[1]:.1f}s")

        # å†…å­˜ç¨³å®šæ€§åˆ†æ
        pytorch_variance = max(pytorch_memories) - min(pytorch_memories)
        if pytorch_variance < 0.5:
            print(f"   âœ… GPUå†…å­˜ä½¿ç”¨ç¨³å®š (æ³¢åŠ¨: {pytorch_variance:.2f}GB)")
        else:
            print(f"   ğŸŸ¡ GPUå†…å­˜ä½¿ç”¨æœ‰æ³¢åŠ¨ (æ³¢åŠ¨: {pytorch_variance:.2f}GB)")

    # æ€§èƒ½ç“¶é¢ˆåˆ†æ
    print(f"\nğŸ” æ€§èƒ½ç“¶é¢ˆåˆ†æ:")
    print(f"{'-' * 50}")

    bottlenecks = []

    if speeds:
        # é¦–Tokenå»¶è¿Ÿç“¶é¢ˆ
        if speeds.get('first_token_latency', 0) > 2.0:
            bottlenecks.append("é¦–Tokenå»¶è¿Ÿè¿‡é«˜ - å¯èƒ½éœ€è¦æ¨¡å‹é¢„çƒ­æˆ–ä¼˜åŒ–åŠ è½½")

        # ç”Ÿæˆé€Ÿåº¦ç“¶é¢ˆ
        if speeds.get('pure_generation_speed', 0) < 15:
            bottlenecks.append("ç”Ÿæˆé€Ÿåº¦åä½ - å¯èƒ½æ˜¯é‡åŒ–ç²¾åº¦æˆ–ç¡¬ä»¶é™åˆ¶")

    if summary:
        # GPUåˆ©ç”¨ç‡ç“¶é¢ˆ
        if summary.get('gpu_usage_avg', 0) < 60:
            bottlenecks.append("GPUåˆ©ç”¨ç‡ä½ - å¯èƒ½å­˜åœ¨CPU-GPUæ•°æ®ä¼ è¾“ç“¶é¢ˆ")

        # CPUç“¶é¢ˆ
        if summary.get('cpu_avg', 0) > 80:
            bottlenecks.append("CPUä½¿ç”¨ç‡é«˜ - æ•°æ®é¢„å¤„ç†å¯èƒ½æˆä¸ºç“¶é¢ˆ")

    # å†…å­˜ç“¶é¢ˆ
    if memory_analysis:
        efficiency = memory_analysis.get('efficiency', {})
        if efficiency.get('memory_efficiency') == 'very_high':
            bottlenecks.append("å†…å­˜ä½¿ç”¨é‡å¤§ - å¯èƒ½é™åˆ¶æ›´å¤§çš„æ‰¹å¤„ç†æˆ–åºåˆ—é•¿åº¦")

    if bottlenecks:
        for i, bottleneck in enumerate(bottlenecks, 1):
            print(f"   {i}. âš ï¸  {bottleneck}")
    else:
        print(f"   âœ… æœªå‘ç°æ˜æ˜¾æ€§èƒ½ç“¶é¢ˆ")

    # æ€»ä½“è¯„ä¼°
    print(f"\nğŸ† æ€»ä½“æ€§èƒ½è¯„ä¼°:")
    print(f"{'-' * 50}")

    overall_score = 0
    max_score = 5

    # è¯„åˆ†æ ‡å‡†
    if speeds:
        # é¦–Tokenå»¶è¿Ÿè¯„åˆ† (20%)
        latency = speeds.get('first_token_latency', 0)
        if latency < 0.5:
            overall_score += 1
        elif latency < 1.0:
            overall_score += 0.8
        elif latency < 2.0:
            overall_score += 0.6
        else:
            overall_score += 0.3

        # ç”Ÿæˆé€Ÿåº¦è¯„åˆ† (40%)
        speed = speeds.get('pure_generation_speed', 0)
        if speed > 30:
            overall_score += 2
        elif speed > 20:
            overall_score += 1.6
        elif speed > 15:
            overall_score += 1.2
        elif speed > 10:
            overall_score += 0.8
        else:
            overall_score += 0.4

    # GPUåˆ©ç”¨ç‡è¯„åˆ† (20%)
    if summary and summary.get('gpu_usage_avg', 0) > 0:
        gpu_usage = summary.get('gpu_usage_avg', 0)
        if gpu_usage > 85:
            overall_score += 1
        elif gpu_usage > 70:
            overall_score += 0.8
        elif gpu_usage > 50:
            overall_score += 0.6
        else:
            overall_score += 0.3

    # å†…å­˜æ•ˆç‡è¯„åˆ† (20%)
    if memory_analysis:
        efficiency = memory_analysis.get('efficiency', {})
        memory_eff = efficiency.get('memory_efficiency', 'unknown')
        if memory_eff == 'good':
            overall_score += 1
        elif memory_eff == 'high':
            overall_score += 0.7
        else:
            overall_score += 0.4

    # è¯„çº§
    percentage = (overall_score / max_score) * 100

    if percentage >= 90:
        grade = "ğŸ† A+ (ä¼˜ç§€)"
        color = "âœ…"
    elif percentage >= 80:
        grade = "ğŸ¥‡ A (è‰¯å¥½)"
        color = "ğŸŸ¢"
    elif percentage >= 70:
        grade = "ğŸ¥ˆ B (ä¸­ç­‰)"
        color = "ğŸŸ¡"
    elif percentage >= 60:
        grade = "ğŸ¥‰ C (åŠæ ¼)"
        color = "ğŸŸ "
    else:
        grade = "âŒ D (éœ€è¦ä¼˜åŒ–)"
        color = "ğŸ”´"

    print(f"   {color} ç»¼åˆè¯„åˆ†: {overall_score:.1f}/{max_score} ({percentage:.1f}%)")
    print(f"   {color} æ€§èƒ½ç­‰çº§: {grade}")

    # æ¨èçš„ä¸‹ä¸€æ­¥è¡ŒåŠ¨
    print(f"\nğŸ¯ æ¨èçš„ä¸‹ä¸€æ­¥è¡ŒåŠ¨:")
    print(f"{'-' * 50}")

    if percentage >= 90:
        print(f"   ğŸ‰ æ€§èƒ½è¡¨ç°ä¼˜ç§€ï¼å¯ä»¥è€ƒè™‘ï¼š")
        print(f"   â€¢ å°è¯•è¿è¡Œæ›´å¤§çš„æ¨¡å‹")
        print(f"   â€¢ å¢åŠ æ‰¹å¤„ç†å¤§å°")
        print(f"   â€¢ æµ‹è¯•æ›´å¤æ‚çš„æ¨ç†ä»»åŠ¡")
    elif percentage >= 70:
        print(f"   ğŸ”§ æ€§èƒ½è‰¯å¥½ï¼Œå¯ä»¥è€ƒè™‘å°å¹…ä¼˜åŒ–ï¼š")
        print(f"   â€¢ æ·»åŠ æ¨¡å‹é¢„çƒ­")
        print(f"   â€¢ è°ƒæ•´é‡åŒ–å‚æ•°")
        print(f"   â€¢ ä¼˜åŒ–è¾“å…¥æ•°æ®æµæ°´çº¿")
    else:
        print(f"   âš¡ éœ€è¦é‡ç‚¹ä¼˜åŒ–ï¼š")
        print(f"   â€¢ æ£€æŸ¥ç¡¬ä»¶é…ç½®")
        print(f"   â€¢ å°è¯•ä¸åŒçš„é‡åŒ–ç­–ç•¥")
        print(f"   â€¢ è€ƒè™‘æ¨¡å‹æˆ–ç¡¬ä»¶å‡çº§")

    # å®æ—¶é€Ÿåº¦å˜åŒ–åˆ†æ (å¦‚æœæœ‰è¶³å¤Ÿæ•°æ®)
    if speeds and 'real_time_intervals' in speeds and len(speeds['real_time_intervals']) > 5:
        print(f"\nğŸ“ˆ å®æ—¶é€Ÿåº¦å˜åŒ–åˆ†æ:")
        print(f"{'-' * 50}")
        intervals = speeds['real_time_intervals']
        speeds_list = [1.0 / interval for interval in intervals if interval > 0]

        if speeds_list:
            min_speed = min(speeds_list)
            max_speed = max(speeds_list)
            avg_speed = sum(speeds_list) / len(speeds_list)

            print(f"   å®æ—¶é€Ÿåº¦èŒƒå›´: {min_speed:.1f} - {max_speed:.1f} tokens/ç§’")
            print(f"   å®æ—¶å¹³å‡é€Ÿåº¦: {avg_speed:.1f} tokens/ç§’")
            print(f"   é€Ÿåº¦ç¨³å®šæ€§: {'ç¨³å®š' if (max_speed - min_speed) < 5 else 'æœ‰æ³¢åŠ¨'}")

    print(f"\n{'=' * 80}")
    print("âœ… ç›‘æ§å®Œæˆ! æ€§èƒ½åˆ†æå·²ç”Ÿæˆ")
    print(f"{'=' * 80}")


if __name__ == "__main__":
    main()